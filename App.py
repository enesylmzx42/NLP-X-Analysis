import streamlit as st
import joblib
import string
import re



users = ["Netflix", "Webtekno", "Acun IlÄ±calÄ±", "Rasim Ozan Kutahyali"]

# some meaningless words in dataset
stop_words = sorted(
    ['Å¡koda','ÉpuÄ±ÊÉÊ','ÉÉ¯nÉ”','É¹Ä±pÉ¹ÉÊŒ','É¹Ä±q',
     'É¹ÇÆƒuÉÉ¹Ê‡s','É¹ÇÉ¥','Ë‡Ï‰Ë‡','Î­Î»Î»Î·Î½Î±','Î­Ï‡Ï‰','Î®ÏÎ¸ÎµÏ‚',
     'Î±Î´ÎµÏÏ†Î­','Î±Î¼Ï†Î¹Î²Î¿Î»Î¯Î±','Î±Ï…Ï„Î®','Î³Î½Ï‰ÏÎ¯Î¶Ï‰','Î´ÎµÎ½','Î´Ï…Î¿',
     'ÎµÎ¯Î¼Î±Î¹','ÎµÎ¯Î½Î±Î¹','ÎµÎ¼Î¬Ï‚','ÎµÎ½Î¸Î¿Ï…ÏƒÎ¹Î¬Î¶Î¿Ï…Î½','Î¶Î®ÏƒÎ¿Ï…Î¼Îµ',
     'Î¸Î±','ÎºÎ¬Î½Î¿Ï…Î½','ÎºÎ±Î¹','ÎºÎ±Î»ÏÏ‚','ÎºÎ±Î¼Î¯Î±','ÎºÎ¿Î¹Î½Î¬','Î¼Î±Î¶Î¯',
     'Î¼Î±Ï‚','Î¼Îµ','Î¼ÎµÎ³Î¬Î»Î±','Î¼Î¹Î±Ï‚','Î¼Î¿Ï…','Î¿Î¹','Î¿Î¹ÎºÎ¿Î³Î­Î½ÎµÎ¹Î¬',
     'Î¿Î¼Î¬Î´Î±','Î¿Î¼Î¬Î´ÎµÏ‚','Ï€Î±Î¯Î¶Î¿Ï…Î½','Ï€Î±Î¹Ï‡Î½Î¯Î´Î¹Î±','Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±',
     'Ï€Î¹ÏƒÏ„ÎµÏÎµÎ¹Ï‚','Ï€Î¿Î»Î»Î¬','Ï€Î¿Î»Ï','Ï€Î¿Ï…','Ï€ÏÎ¬Î³Î¼Î±Ï„Î±','Ï€ÏÏŒÎ¸Ï…Î¼Î±',
     'Ï€ÏŒÎ»Î·','ÏƒÎµ','ÏƒÏ„Î·Î½','Ï„Î±','Ï„Î·Î½','Ï„Î¿','Ï„Ï‰Î½','Ï…Ï€Î­ÏÎ¿Ï‡Î±',
     'Ï†Î¹Î»Î¯Î±Ï‚','Ï‡Î±ÏÎ¿ÏÎ¼ÎµÎ½Î¿','Ï‡Î±ÏÎ¿ÏÎ¼ÎµÎ½Î¿Ï‚','Ï‡Ï‰ÏÏÎ½','ÏŒÎ¼Î¿ÏÏ†Î·Ï‚',
     'ÏŒÎ½ÎµÎ¹ÏÎ±','ÏŒÏ„Î¹','â¿áµ‰áµˆáµ‰â¿','ãã¸','ãƒspoiler','ãƒ½ã¤','ë‚´ì¼',
     'ë‹¨ë…ê³µê°œ','ì˜¤í›„','ğ“ğ“œğ“Ÿğ“˜','ğ“‘ğ“²ğ”ƒ','ğ“¨ğ“ğ“','ğ“²ğ”ƒ','ğ“¸ğ“µğ“ªğ“¬ğ“ªğ“°'
    ])


class App:
    def __init__(self):
        self.model_NB = joblib.load("./models/model_NB.pkl")
        self.vectorizer = joblib.load("./models/vectorizer.pkl")
        
    def clean(self, tweet):
        """
        This function removes meaningless words, punctuation marks, numbers from tweets, transforming them into a simpler form.

        Parameters:
        tweet (str): The tweet to be cleaned

        Returns:
        row (str): Cleaned tweet
        """
        satirlar = tweet.replace("\n", " ") # Replaces \n with a space in the dataset.
        satirlar = re.sub("[0-9]+", "", satirlar) # Removes numbers from the data.
        satirlar = [t for t in satirlar.split() if t not in stop_words] # Removes meaningless words from the data.
        
        return " ".join(satirlar).lower().translate(str.maketrans("", "", string.punctuation)) # Cleans punctuation marks from the data.

          
    def tweet_analyse(self, tweet):
        tweet = self.clean(tweet)
        tweet_vec = self.vectorizer.transform([tweet])
        
        result_NB = self.model_NB.predict_proba(tweet_vec)[0]
        
        return result_NB
    



    def run(self):
       st.title("Tweet Analysis System")
       
       st.markdown(
           """
           <style>
           .stApp{
               background-color: #000;
           }
           .analyze-button {
               background-color: #C6C6C6;
               border: none;
               color: black;
               text-align: center;
               text-decoration: none;
               display: inline-block;
               cursor: pointer;
               border-radius: 2px;
           }
           </style>
           """,
           unsafe_allow_html=True
       )
       
       form = st.form("tweet_analyse_form")
       tweet = form.text_input("Type the tweet you want analyzed:")
       submitted = form.form_submit_button("Analyse")
       
       if submitted:
           if tweet == "" or tweet == " ":
               st.write("You didn't write any tweets!")
           else:
               result_NB = self.tweet_analyse(tweet)
               max_index = result_NB.argmax()
   
               st.markdown("<h4 style='text-align: center;'>Results of Multi-Nomial Naive Bayes</h4>", unsafe_allow_html=True)
               
               for i, score in enumerate(result_NB):
                   if i == max_index:
                       st.markdown(f"<button class='analyze-button'>{users[i]}</button>", unsafe_allow_html=True)
                   else:
                       st.markdown(f"{users[i]} \t")


app = App()
app.run()