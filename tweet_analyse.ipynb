{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2eeb359-3dbd-4b57-ac2e-98e0438f22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re # regular expressions\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from joblib import Parallel, delayed \n",
    "import joblib \n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cb79a0-7e1a-4cbf-abd5-5340ae67c4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>@valenciaessek Mutlu yıllar!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Yeni sezon şimdi yayında.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Geceye yeni yıldan bir beklenti bırak.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Özür dilerim ben de spoiler verdim, 20 puanla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>2022 yılı hatalar testi:\\n\\nSpoiler verdim (20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                                              tweet\n",
       "0  netflixturkiye                       @valenciaessek Mutlu yıllar!\n",
       "1  netflixturkiye                          Yeni sezon şimdi yayında.\n",
       "2  netflixturkiye             Geceye yeni yıldan bir beklenti bırak.\n",
       "3  netflixturkiye  Özür dilerim ben de spoiler verdim, 20 puanla ...\n",
       "4  netflixturkiye  2022 yılı hatalar testi:\\n\\nSpoiler verdim (20..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datas/temizlenmemis_tweets.csv\")\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cacfa2d-8840-4bbc-aa60-de3eb07a6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweet):\n",
    "    \"\"\"\n",
    "    This function converts tweets into a simpler form by removing meaningless words, punctuation marks, and numbers.\n",
    "\n",
    "    Parameters:\n",
    "    tweet (str): The tweet to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    row (str): The cleaned tweet.\n",
    "    \"\"\"\n",
    "    satirlar = tweet.replace(\"\\n\", \" \")  # Replace \"\\n\" with \" \" (space) in the dataset.\n",
    "    satirlar = re.sub(\"[0-9]+\", \"\", satirlar) # Remove numbers from the data.\n",
    "    satirlar = [t for t in satirlar.split()if t not in utils.stop_words] # Remove meaningless words from the data.\n",
    "    \n",
    "    return \" \".join(satirlar).lower().translate(str.maketrans(\"\", \"\", string.punctuation)) # Clean punctuation marks from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5b0a81-9723-4155-b6bb-f91e834f1099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>@valenciaessek Mutlu yıllar!</td>\n",
       "      <td>valenciaessek mutlu yıllar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Yeni sezon şimdi yayında.</td>\n",
       "      <td>yeni sezon şimdi yayında</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Geceye yeni yıldan bir beklenti bırak.</td>\n",
       "      <td>geceye yeni yıldan bir beklenti bırak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Özür dilerim ben de spoiler verdim, 20 puanla ...</td>\n",
       "      <td>özür dilerim ben de spoiler verdim puanla kapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>2022 yılı hatalar testi:\\n\\nSpoiler verdim (20...</td>\n",
       "      <td>yılı hatalar testi spoiler verdim  puan önerdi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11460</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Bu şerefsizliğe alet olarak bu haysiyetsizce y...</td>\n",
       "      <td>bu şerefsizliğe alet olarak bu haysiyetsizce y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11461</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Aleni yalanlarla bana bu şerefsizliği yapan fi...</td>\n",
       "      <td>aleni yalanlarla bana bu şerefsizliği yapan fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11462</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Bu yalan açıklamaları yapan şahsa ve dolandırı...</td>\n",
       "      <td>bu yalan açıklamaları yapan şahsa ve dolandırı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11463</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Ben asla böyle bir dilekçe vermedim.Hakkımda b...</td>\n",
       "      <td>ben asla böyle bir dilekçe vermedimhakkımda ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Benim bir mahkemede “Ben Erdoğan’ı destekliyor...</td>\n",
       "      <td>benim bir mahkemede “ben erdoğan’ı destekliyor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11465 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                                              tweet  \\\n",
       "0      netflixturkiye                       @valenciaessek Mutlu yıllar!   \n",
       "1      netflixturkiye                          Yeni sezon şimdi yayında.   \n",
       "2      netflixturkiye             Geceye yeni yıldan bir beklenti bırak.   \n",
       "3      netflixturkiye  Özür dilerim ben de spoiler verdim, 20 puanla ...   \n",
       "4      netflixturkiye  2022 yılı hatalar testi:\\n\\nSpoiler verdim (20...   \n",
       "...               ...                                                ...   \n",
       "11460     RasimOzan_K  Bu şerefsizliğe alet olarak bu haysiyetsizce y...   \n",
       "11461     RasimOzan_K  Aleni yalanlarla bana bu şerefsizliği yapan fi...   \n",
       "11462     RasimOzan_K  Bu yalan açıklamaları yapan şahsa ve dolandırı...   \n",
       "11463     RasimOzan_K  Ben asla böyle bir dilekçe vermedim.Hakkımda b...   \n",
       "11464     RasimOzan_K  Benim bir mahkemede “Ben Erdoğan’ı destekliyor...   \n",
       "\n",
       "                                                   clean  \n",
       "0                             valenciaessek mutlu yıllar  \n",
       "1                               yeni sezon şimdi yayında  \n",
       "2                  geceye yeni yıldan bir beklenti bırak  \n",
       "3      özür dilerim ben de spoiler verdim puanla kapa...  \n",
       "4      yılı hatalar testi spoiler verdim  puan önerdi...  \n",
       "...                                                  ...  \n",
       "11460  bu şerefsizliğe alet olarak bu haysiyetsizce y...  \n",
       "11461  aleni yalanlarla bana bu şerefsizliği yapan fi...  \n",
       "11462  bu yalan açıklamaları yapan şahsa ve dolandırı...  \n",
       "11463  ben asla böyle bir dilekçe vermedimhakkımda ba...  \n",
       "11464  benim bir mahkemede “ben erdoğan’ı destekliyor...  \n",
       "\n",
       "[11465 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean\"] = df.apply(lambda row: clean(row[\"tweet\"]), axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a237ac-3a43-4195-8f91-be20ec681386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['netflixturkiye', 'webtekno', 'acunilicali', 'RasimOzan_K']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users in dataset\n",
    "users = list(df[\"username\"].unique())\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72156a50-6f5e-40ec-8422-d7bc65ddc12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiketle(row, users):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs Label Encoding on the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    row (str): The row to be Label Encoded.\n",
    "    users (list): The list of users present in the dataset to be referenced during Label Encoding.\n",
    "    \n",
    "    Returns:\n",
    "    (int)\n",
    "    \"\"\"\n",
    "\n",
    "    if row[\"username\"] == users[0]:\n",
    "        return 0 \n",
    "    elif row[\"username\"] == users[1]:\n",
    "        return 1\n",
    "    elif row[\"username\"] == users[2]:\n",
    "        return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58369f4-ca80-4cef-a8e4-140c217ae737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>@valenciaessek Mutlu yıllar!</td>\n",
       "      <td>valenciaessek mutlu yıllar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Yeni sezon şimdi yayında.</td>\n",
       "      <td>yeni sezon şimdi yayında</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Geceye yeni yıldan bir beklenti bırak.</td>\n",
       "      <td>geceye yeni yıldan bir beklenti bırak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>Özür dilerim ben de spoiler verdim, 20 puanla ...</td>\n",
       "      <td>özür dilerim ben de spoiler verdim puanla kapa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>netflixturkiye</td>\n",
       "      <td>2022 yılı hatalar testi:\\n\\nSpoiler verdim (20...</td>\n",
       "      <td>yılı hatalar testi spoiler verdim  puan önerdi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11460</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Bu şerefsizliğe alet olarak bu haysiyetsizce y...</td>\n",
       "      <td>bu şerefsizliğe alet olarak bu haysiyetsizce y...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11461</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Aleni yalanlarla bana bu şerefsizliği yapan fi...</td>\n",
       "      <td>aleni yalanlarla bana bu şerefsizliği yapan fi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11462</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Bu yalan açıklamaları yapan şahsa ve dolandırı...</td>\n",
       "      <td>bu yalan açıklamaları yapan şahsa ve dolandırı...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11463</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Ben asla böyle bir dilekçe vermedim.Hakkımda b...</td>\n",
       "      <td>ben asla böyle bir dilekçe vermedimhakkımda ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>RasimOzan_K</td>\n",
       "      <td>Benim bir mahkemede “Ben Erdoğan’ı destekliyor...</td>\n",
       "      <td>benim bir mahkemede “ben erdoğan’ı destekliyor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11465 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                                              tweet  \\\n",
       "0      netflixturkiye                       @valenciaessek Mutlu yıllar!   \n",
       "1      netflixturkiye                          Yeni sezon şimdi yayında.   \n",
       "2      netflixturkiye             Geceye yeni yıldan bir beklenti bırak.   \n",
       "3      netflixturkiye  Özür dilerim ben de spoiler verdim, 20 puanla ...   \n",
       "4      netflixturkiye  2022 yılı hatalar testi:\\n\\nSpoiler verdim (20...   \n",
       "...               ...                                                ...   \n",
       "11460     RasimOzan_K  Bu şerefsizliğe alet olarak bu haysiyetsizce y...   \n",
       "11461     RasimOzan_K  Aleni yalanlarla bana bu şerefsizliği yapan fi...   \n",
       "11462     RasimOzan_K  Bu yalan açıklamaları yapan şahsa ve dolandırı...   \n",
       "11463     RasimOzan_K  Ben asla böyle bir dilekçe vermedim.Hakkımda b...   \n",
       "11464     RasimOzan_K  Benim bir mahkemede “Ben Erdoğan’ı destekliyor...   \n",
       "\n",
       "                                                   clean  labels  \n",
       "0                             valenciaessek mutlu yıllar       0  \n",
       "1                               yeni sezon şimdi yayında       0  \n",
       "2                  geceye yeni yıldan bir beklenti bırak       0  \n",
       "3      özür dilerim ben de spoiler verdim puanla kapa...       0  \n",
       "4      yılı hatalar testi spoiler verdim  puan önerdi...       0  \n",
       "...                                                  ...     ...  \n",
       "11460  bu şerefsizliğe alet olarak bu haysiyetsizce y...       3  \n",
       "11461  aleni yalanlarla bana bu şerefsizliği yapan fi...       3  \n",
       "11462  bu yalan açıklamaları yapan şahsa ve dolandırı...       3  \n",
       "11463  ben asla böyle bir dilekçe vermedimhakkımda ba...       3  \n",
       "11464  benim bir mahkemede “ben erdoğan’ı destekliyor...       3  \n",
       "\n",
       "[11465 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Label Encoding on the dataset\n",
    "df[\"labels\"] = df.apply(lambda row:  etiketle(row, users), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8a2a0e-b63e-4ec8-a645-8efbaffb2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean.to_numpy() # Converting cleaned tweets to a numpy array\n",
    "y = df.labels.to_numpy() # Converting labels of tweets to a numpy array\n",
    "\n",
    "# Splitting the dataset into 80% training and 20% test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting tweets into vectors using the TF-IDF method\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768e2a95-7974-44a6-8bd0-ac5f0ecd1511",
   "metadata": {},
   "source": [
    "### What is Multinomial Naive Bayes?\n",
    "Multinomial Naive Bayes (MultinomialNB) is a probabilistic classification algorithm based on Bayes' theorem and certain assumptions. This algorithm is particularly suitable for text classification problems based on word counts. Naive Bayes classifiers are simple yet powerful and fast algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d155b1-810c-4752-918f-1f8367a6a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB train accuracy: 0.9615133013519407\n",
      "NB test accuracy: 0.8634976013955517\n"
     ]
    }
   ],
   "source": [
    "# Training the Multinomial Naive Bayes model\n",
    "model_NB = MultinomialNB()\n",
    "model_NB.fit(X_train, y_train)\n",
    "\n",
    "# Model's acc on the dataset\n",
    "print(\"NB train accuracy:\", model_NB.score(X_train, y_train))\n",
    "print(\"NB test accuracy:\", model_NB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e875698-328c-4a54-a2a7-7b63a2811e79",
   "metadata": {},
   "source": [
    "### What is Decision Tree Classifier?\n",
    "Decision Tree Classifier is a classifier used for classification problems. Decision trees classify the examples in a dataset by splitting them into branches based on their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a549e1-571f-46da-8bee-fa576466dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT train accuracy: 0.9996729175752289\n",
      "DT test accuracy: 0.7056258177060619\n"
     ]
    }
   ],
   "source": [
    "# Training the Decision Tree Classifier model\n",
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(X_train, y_train)\n",
    "\n",
    "# Model's acc on the dataset\n",
    "print(\"DT train accuracy:\", model_DT.score(X_train, y_train))\n",
    "print(\"DT test accuracy:\", model_DT.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4289ebf-e943-4851-b007-ce28abde8e51",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "978e0041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: [0]\n",
      "DT: [1]\n",
      "Netflix: \tNB: 77.82 \tDT: 0.0\n",
      "Webtekno: \tNB: 17.24 \tDT: 100.0\n",
      "Acun Ilicali: \tNB: 0.27 \tDT: 0.0\n",
      "Rasim Ozan Kutahyali: \tNB: 4.66 \tDT0.0\n"
     ]
    }
   ],
   "source": [
    "tweet = clean(\"İzlediğin son filmi söyle, nasıl hissettiğini tahmin edeyim.\")\n",
    "tweet_vec = vectorizer.transform([tweet])\n",
    "# Netflix: 0\n",
    "# Webtekno: 1\n",
    "# Acun: 2\n",
    "# ROK: 3\n",
    "print(\"NB:\", model_NB.predict(tweet_vec))\n",
    "print(\"DT:\", model_DT.predict(tweet_vec))\n",
    "\n",
    "result_NB = model_NB.predict_proba(tweet_vec)\n",
    "result_DT = model_DT.predict_proba(tweet_vec)\n",
    "print(\n",
    "    f\"Netflix: \\tNB: {round(100*result_NB[0][0],2)} \\tDT: {round(100*result_DT[0][0],2)}\\n\"\n",
    "    f\"Webtekno: \\tNB: {round(100*result_NB[0][1],2)} \\tDT: {round(100*result_DT[0][1],2)}\\n\"\n",
    "    f\"Acun Ilicali: \\tNB: {round(100*result_NB[0][2],2)} \\tDT: {round(100*result_DT[0][2],2)}\\n\"\n",
    "    f\"Rasim Ozan Kutahyali: \\tNB: {round(100*result_NB[0][3],2)} \\tDT{round(100*result_DT[0][3],2)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f67f55-0534-4fca-aa45-89f9f4a9f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_analyse(tweet):\n",
    "    tweet = clean(tweet)\n",
    "    tweet_vec = vectorizer.transform([tweet])\n",
    "    # Netflix: 0\n",
    "    # Webtekno: 1\n",
    "    # Acun: 2\n",
    "    # ROK: 3\n",
    "    print(\"NB:\", model_NB.predict(tweet_vec))\n",
    "    print(\"DT:\", model_DT.predict(tweet_vec))\n",
    "    \n",
    "    result_NB = model_NB.predict_proba(tweet_vec)\n",
    "    result_DT = model_DT.predict_proba(tweet_vec)\n",
    "    print(\n",
    "        f\"Netflix: \\tNB: {round(100*result_NB[0][0],2)} \\tDT: {round(100*result_DT[0][0],2)}\\n\"\n",
    "        f\"Webtekno: \\tNB: {round(100*result_NB[0][1],2)} \\tDT: {round(100*result_DT[0][1],2)}\\n\"\n",
    "        f\"Acun Ilicali: \\tNB: {round(100*result_NB[0][2],2)} \\tDT: {round(100*result_DT[0][2],2)}\\n\"\n",
    "        f\"Rasim Ozan Kutahyali: \\tNB: {round(100*result_NB[0][3],2)} \\tDT{round(100*result_DT[0][3],2)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43e7eaa8-7515-4a71-b3d8-ee47307ed56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: [0]\n",
      "DT: [1]\n",
      "Netflix: \tNB: 77.82 \tDT: 0.0\n",
      "Webtekno: \tNB: 17.24 \tDT: 100.0\n",
      "Acun Ilicali: \tNB: 0.27 \tDT: 0.0\n",
      "Rasim Ozan Kutahyali: \tNB: 4.66 \tDT0.0\n"
     ]
    }
   ],
   "source": [
    "tweet_analyse(\"İzlediğin son filmi söyle, nasıl hissettiğini tahmin edeyim.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28bdd6-e393-4738-aafc-d368dc22e2dc",
   "metadata": {},
   "source": [
    "### save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a78af64-6ee8-40c2-b734-1ab96349daa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/vectorizer.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, \"./models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf545bfc-03de-4751-8f98-215f43644605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/model_DT.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_NB, './models/model_NB.pkl')\n",
    "joblib.dump(model_DT, './models/model_DT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499adb0-cd18-4cc2-b02e-882ce659822d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
